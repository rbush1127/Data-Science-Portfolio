{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package, Data, and Base Error Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from math import sqrt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, actual):\n",
    "    mse = mean_squared_error(predictions, actual)\n",
    "    rmse = sqrt(mse)\n",
    "    residuals = [predictions-actual]\n",
    "    return(rmse, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_excel('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\PGA Finish Projections\\\\PGA Finish Projections_modeling data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Features\n",
    "features = ['sg_putt','sg_arg','sg_app','sg_ott','sg_t2g']\n",
    "\n",
    "# Lagged Strokes-Gained Feature\n",
    "lag_1_fields = ['sg_putt1','sg_arg1','sg_app1','sg_ott1','sg_t2g1']\n",
    "lag_2_fields = ['sg_putt2','sg_arg2','sg_app2','sg_ott2','sg_t2g2']\n",
    "lag_3_fields = ['sg_putt3','sg_arg3','sg_app3','sg_ott3','sg_t2g3']\n",
    "\n",
    "sg_fields = lag_1_fields+lag_2_fields+lag_3_fields\n",
    "\n",
    "# Player, Course, and Tournament with Lagged Strokes-Gained\n",
    "pct_sg_fields = ['player_id']+['tournament_id']+['course_id']+sg_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_1_fields = ['sg_putt1','sg_arg1','sg_app1','sg_ott1','sg_t2g1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lag_1_features, df_lag_1_target = df_model[lag_1_fields], df_model['strokes_rel_par']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lag_1_features, test_lag_1_features, train_lag_1_target, test_lag_1_target = train_test_split(df_lag_1_features, df_lag_1_target, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rf_fit(train_features, test_features, train_target, test_target):\n",
    "    \n",
    "    rf_base = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "    rf_base.fit(train_features, train_target)\n",
    "    predictions_base = rf_base.predict(test_features)\n",
    "    errors_base, _ = rmse(predictions_base, test_target)\n",
    "    base_rmse = round(np.mean(errors_base), 2)\n",
    "    \n",
    "    return(base_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rmse = simple_rf_fit(train_features = train_lag_1_features, test_features = test_lag_1_features, \n",
    "                          train_target = train_lag_1_target, test_target = test_lag_1_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = ['player', 'tournament_name', 'course']\n",
    "    \n",
    "with open('base_features.pkl', 'wb') as outfile:\n",
    "    pickle.dump(features, outfile)\n",
    "    \n",
    "with open('sg_lag_features.pkl', 'wb') as outfile:\n",
    "    pickle.dump(sg_fields, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Feature Engineering & Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data we're using, we have used <em>place_adj</em> which assigned a finishing place of 80 to a player who missed the cut.  In most tournaments, half of the players who begin playing on Thursday are cut from the tournament at the end of Friday's round.  This leads to an imbalanced regression target variable, and limits the ability of the model to make accurate predictions.\n",
    "\n",
    "In the plot below, the histogram shows the distribution of finishes in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9427 16549\n"
     ]
    }
   ],
   "source": [
    "dfa = df_model.loc[df_model['place_adj']==80]\n",
    "dfb = df_model.loc[df_model['place_adj']<80]\n",
    "print(dfa.shape[0], dfb.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "finishes = df_model['place_adj'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = pl.hist(finishes, range = (0,80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve predictive power, I will split our model into two phases:\n",
    "\n",
    "<ol>\n",
    "    <li>Classification algorithm which distinguishes players who will make the cut from those who won't</li>\n",
    "    <li>Regression algorithm which aims to predict how a player will finish if they make the cut</li>\n",
    "</ol>\n",
    "\n",
    "For the former I will tune a Support Vector Machine (SVM) which identifies players who are likely to make the cut.  For the players who make the cut, an XG Boost regressor will then be used to predict a player's score relative to par.  Error reduction will be evaluated relative to the previously-established <em>base_error</em>, which represents the prediction of a simple 100-tree RandomForest estimator using nothing but last-week's strokes-gained data for each player.  For streamlined model-checking and -tuning, I will use the following functions to conduct a random hyperparameter grid search.\n",
    "\n",
    "<ol>\n",
    "    <li><em>xgb_param_tune</em></li>\n",
    "    <li><em>svm_param_tune</em></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_param_tune(train_features, train_target, test_features, test_target, base_rmse, \n",
    "                   param_grid, n_iter, cv, verbose, random_state):\n",
    "    \n",
    "    xg = XGBRegressor()\n",
    "    xg_random = RandomizedSearchCV(estimator = xg, param_distributions = param_grid, \n",
    "                                   n_jobs = -1, n_iter = n_iter, cv = cv, verbose = verbose, random_state = random_state)\n",
    "    xg_random.fit(train_features, train_target)\n",
    "    best_params = xg_random.best_params_\n",
    "    \n",
    "    xg_tuned = XGBRegressor(learning_rate = best_params['learning_rate'], n_estimators = best_params['n_estimators'],\n",
    "                            gamma = best_params['gamma'], colsample_bytree = best_params['colsample_bytree'], \n",
    "                            subsample = best_params['subsample'], max_depth = best_params['max_depth'], \n",
    "                            n_jobs = -1, random_state = random_state)\n",
    "    xg_tuned.fit(train_features, train_target)\n",
    "    predictions = xg_tuned.predict(test_features)\n",
    "    \n",
    "    residuals, _ = rmse(predictions, test_target)\n",
    "    error = np.mean(residuals)\n",
    "    error_pct_diff = round(100*(error-base_rmse)/base_rmse, 2)\n",
    "    \n",
    "    print_string = '%s: %s' % ('Tuned XG Boost Model with Player, Course, Tournament, and Lagged Strokes-Gained', error_pct_diff)\n",
    "    print(print_string+'%'+'\\n')\n",
    "    \n",
    "    return(best_params, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_param_tune(train_features, test_features, train_target, test_target, random_grid, n_iter, cv, scoring):\n",
    "    svm = SVC()\n",
    "    \n",
    "    svm_random = RandomizedSearchCV(estimator = svm, param_distributions = random_grid, n_iter = n_iter, cv = cv, \n",
    "                                    verbose = 3, random_state = 42, n_jobs = -1, scoring = scoring)\n",
    "    svm_random.fit(train_features, train_target)\n",
    "    best_params = svm_random.best_params_\n",
    "    \n",
    "    svm = SVC(C = best_params['C'], gamma = best_params['gamma'], tol = best_params['tol'])\n",
    "    svm.fit(train_features, train_target)\n",
    "    \n",
    "    class_predictions = svm.predict(test_features)\n",
    "    cm = confusion_matrix(test_target, class_predictions)\n",
    "    \n",
    "    accuracy = (cm[0,0]+cm[1,1])/np.sum(cm)\n",
    "    precision = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "    recall = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    \n",
    "    return(best_params, (accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By converting the player, tournament, and course values to one-hot vector encodings, we are allowing the decision trees to effectively \"turn on\" a model for a particular player-event pairing.  In the following section, we will evaluate whether the one-hot encoding approach explains player finishes better than simply leaving player, tournament, and course as columnar values.  If the error decrease is greater, we can conclude that one-hot encoding is a better categorical variable data representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>tournament_name</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Baddeley</td>\n",
       "      <td>AT&amp;T Byron Nelson</td>\n",
       "      <td>TPC Craig Ranch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Baddeley</td>\n",
       "      <td>Valspar Championship</td>\n",
       "      <td>Innisbrook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Baddeley</td>\n",
       "      <td>AT&amp;T Pebble Beach Pro-Am</td>\n",
       "      <td>Pebble Beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Baddeley</td>\n",
       "      <td>Farmers Insurance Open</td>\n",
       "      <td>Torrey Pines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Baddeley</td>\n",
       "      <td>The American Express</td>\n",
       "      <td>La Quinta CC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           player           tournament_name           course\n",
       "0  Aaron Baddeley         AT&T Byron Nelson  TPC Craig Ranch\n",
       "1  Aaron Baddeley      Valspar Championship       Innisbrook\n",
       "2  Aaron Baddeley  AT&T Pebble Beach Pro-Am     Pebble Beach\n",
       "3  Aaron Baddeley    Farmers Insurance Open     Torrey Pines\n",
       "4  Aaron Baddeley      The American Express     La Quinta CC"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_id = df_model[indices]\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sg_putt1</th>\n",
       "      <th>sg_arg1</th>\n",
       "      <th>sg_app1</th>\n",
       "      <th>sg_ott1</th>\n",
       "      <th>sg_t2g1</th>\n",
       "      <th>sg_putt2</th>\n",
       "      <th>sg_arg2</th>\n",
       "      <th>sg_app2</th>\n",
       "      <th>sg_ott2</th>\n",
       "      <th>sg_t2g2</th>\n",
       "      <th>sg_putt3</th>\n",
       "      <th>sg_arg3</th>\n",
       "      <th>sg_app3</th>\n",
       "      <th>sg_ott3</th>\n",
       "      <th>sg_t2g3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.84</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-2.47</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-2.47</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.14</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.59</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sg_putt1  sg_arg1  sg_app1  sg_ott1  sg_t2g1  sg_putt2  sg_arg2  sg_app2  \\\n",
       "0      1.84    -0.73    -0.39    -1.21    -2.33      0.73    -0.41    -2.67   \n",
       "1      0.73    -0.41    -2.67     0.60    -2.47     -0.59     0.38     0.42   \n",
       "2     -0.59     0.38     0.42    -2.04    -1.25     -3.14    -0.72     0.07   \n",
       "3     -3.14    -0.72     0.07    -0.22    -0.86      1.59    -0.94     0.19   \n",
       "4      1.59    -0.94     0.19    -0.35    -1.09     -0.20     1.07    -1.81   \n",
       "\n",
       "   sg_ott2  sg_t2g2  sg_putt3  sg_arg3  sg_app3  sg_ott3  sg_t2g3  \n",
       "0     0.60    -2.47     -0.59     0.38     0.42    -2.04    -1.25  \n",
       "1    -2.04    -1.25     -3.14    -0.72     0.07    -0.22    -0.86  \n",
       "2    -0.22    -0.86      1.59    -0.94     0.19    -0.35    -1.09  \n",
       "3    -0.35    -1.09     -0.20     1.07    -1.81    -0.84    -1.58  \n",
       "4    -0.84    -1.58     -0.11     0.26     0.04     0.08     0.38  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = df_model[sg_fields]\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oh_player = pd.get_dummies(df_id['player'], prefix = 'player')\n",
    "df_oh_tournament = pd.get_dummies(df_id['tournament_name'], prefix = 'tournament')\n",
    "df_oh_course = pd.get_dummies(df_id['course'], prefix = 'course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm1 = pd.merge(df_oh_player, df_oh_tournament, left_index = True, right_index = True)\n",
    "dfm2 = pd.merge(dfm1, df_oh_course, left_index = True, right_index = True)\n",
    "df_model_oh = pd.merge(dfm2, df_feat, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh_features, test_oh_features, train_oh_target, test_oh_target = train_test_split(df_model_oh, df_model['strokes_rel_par'], test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 23605 rows and 23605 target measurements\n",
      "The test dataset has 2623 rows and 2623 target measurements\n"
     ]
    }
   ],
   "source": [
    "print('The train dataset has %s rows and %s target measurements' % (len(train_oh_features.iloc[:,0]), len(train_oh_target)))\n",
    "print('The test dataset has %s rows and %s target measurements' % (len(test_oh_features.iloc[:,0]), len(test_oh_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_rmse = simple_rf_fit(train_features = train_oh_features, test_features = test_oh_features, \n",
    "                        train_target = train_oh_target, test_target = test_oh_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoding Percent Error Reduction: -15.97%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "error_pct_diff = round(100*(oh_rmse-base_rmse)/base_rmse, 2)\n",
    "\n",
    "print_string = '%s: %s' % ('One-Hot Encoding Percent Error Reduction', error_pct_diff)\n",
    "print(print_string+'%'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ordered Strokes-Gained Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, we will evaluate whether the model performs better with a notion of strokes-gained sequence (e.g. 3 weeks ago putting was very poor, then it improved a bit a week later, and last week the player was on fire), or if having a strong performance in the last 3 weeks is a good indicator of whether they will perform well this week.  If the error decrease is greater, we will conclude that storing the last 3 weeks of strokes-gained data as maximum, median, and minimum results in better predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_feat(df, features):\n",
    "    features_minmax = []\n",
    "    for feature in features:\n",
    "        features_minmax = features_minmax+[feature+'_max', feature+'_med', feature+'_min']\n",
    "        \n",
    "    min_max_df = pd.DataFrame(0, index = df.index, columns = features_minmax)\n",
    "    \n",
    "    for feature in features:\n",
    "        min_max_df[[feature+'_min', feature+'_med',feature+'_max']] = np.sort(df[[feature+'1',feature+'2',feature+'3']].values,1)\n",
    "        \n",
    "    return(min_max_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sg_putt1</th>\n",
       "      <th>sg_arg1</th>\n",
       "      <th>sg_app1</th>\n",
       "      <th>sg_ott1</th>\n",
       "      <th>sg_t2g1</th>\n",
       "      <th>sg_putt2</th>\n",
       "      <th>sg_arg2</th>\n",
       "      <th>sg_app2</th>\n",
       "      <th>sg_ott2</th>\n",
       "      <th>sg_t2g2</th>\n",
       "      <th>sg_putt3</th>\n",
       "      <th>sg_arg3</th>\n",
       "      <th>sg_app3</th>\n",
       "      <th>sg_ott3</th>\n",
       "      <th>sg_t2g3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.84</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-2.47</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-2.47</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.14</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.59</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sg_putt1  sg_arg1  sg_app1  sg_ott1  sg_t2g1  sg_putt2  sg_arg2  sg_app2  \\\n",
       "0      1.84    -0.73    -0.39    -1.21    -2.33      0.73    -0.41    -2.67   \n",
       "1      0.73    -0.41    -2.67     0.60    -2.47     -0.59     0.38     0.42   \n",
       "2     -0.59     0.38     0.42    -2.04    -1.25     -3.14    -0.72     0.07   \n",
       "3     -3.14    -0.72     0.07    -0.22    -0.86      1.59    -0.94     0.19   \n",
       "4      1.59    -0.94     0.19    -0.35    -1.09     -0.20     1.07    -1.81   \n",
       "\n",
       "   sg_ott2  sg_t2g2  sg_putt3  sg_arg3  sg_app3  sg_ott3  sg_t2g3  \n",
       "0     0.60    -2.47     -0.59     0.38     0.42    -2.04    -1.25  \n",
       "1    -2.04    -1.25     -3.14    -0.72     0.07    -0.22    -0.86  \n",
       "2    -0.22    -0.86      1.59    -0.94     0.19    -0.35    -1.09  \n",
       "3    -0.35    -1.09     -0.20     1.07    -1.81    -0.84    -1.58  \n",
       "4    -0.84    -1.58     -0.11     0.26     0.04     0.08     0.38  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_minmax = min_max_feat(df_feat, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sg_putt_max</th>\n",
       "      <th>sg_putt_med</th>\n",
       "      <th>sg_putt_min</th>\n",
       "      <th>sg_arg_max</th>\n",
       "      <th>sg_arg_med</th>\n",
       "      <th>sg_arg_min</th>\n",
       "      <th>sg_app_max</th>\n",
       "      <th>sg_app_med</th>\n",
       "      <th>sg_app_min</th>\n",
       "      <th>sg_ott_max</th>\n",
       "      <th>sg_ott_med</th>\n",
       "      <th>sg_ott_min</th>\n",
       "      <th>sg_t2g_max</th>\n",
       "      <th>sg_t2g_med</th>\n",
       "      <th>sg_t2g_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.84</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.59</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.59</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.59</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sg_putt_max  sg_putt_med  sg_putt_min  sg_arg_max  sg_arg_med  sg_arg_min  \\\n",
       "0         1.84         0.73        -0.59        0.38       -0.41       -0.73   \n",
       "1         0.73        -0.59        -3.14        0.38       -0.41       -0.72   \n",
       "2         1.59        -0.59        -3.14        0.38       -0.72       -0.94   \n",
       "3         1.59        -0.20        -3.14        1.07       -0.72       -0.94   \n",
       "4         1.59        -0.11        -0.20        1.07        0.26       -0.94   \n",
       "\n",
       "   sg_app_max  sg_app_med  sg_app_min  sg_ott_max  sg_ott_med  sg_ott_min  \\\n",
       "0        0.42       -0.39       -2.67        0.60       -1.21       -2.04   \n",
       "1        0.42        0.07       -2.67        0.60       -0.22       -2.04   \n",
       "2        0.42        0.19        0.07       -0.22       -0.35       -2.04   \n",
       "3        0.19        0.07       -1.81       -0.22       -0.35       -0.84   \n",
       "4        0.19        0.04       -1.81        0.08       -0.35       -0.84   \n",
       "\n",
       "   sg_t2g_max  sg_t2g_med  sg_t2g_min  \n",
       "0       -1.25       -2.33       -2.47  \n",
       "1       -0.86       -1.25       -2.47  \n",
       "2       -0.86       -1.09       -1.25  \n",
       "3       -0.86       -1.09       -1.58  \n",
       "4        0.38       -1.09       -1.58  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_minmax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm1 = pd.merge(df_oh_player, df_oh_tournament, left_index = True, right_index = True)\n",
    "dfm2 = pd.merge(dfm1, df_oh_course, left_index = True, right_index = True)\n",
    "df_model_oh_minmax = pd.merge(dfm2, df_feat_minmax, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_Aaron Baddeley</th>\n",
       "      <th>player_Aaron Wise</th>\n",
       "      <th>player_Abraham Ancer</th>\n",
       "      <th>player_Adam Hadwin</th>\n",
       "      <th>player_Adam Long</th>\n",
       "      <th>player_Adam Schenk</th>\n",
       "      <th>player_Adam Scott</th>\n",
       "      <th>player_Adam Svensson</th>\n",
       "      <th>player_Akshay Bhatia</th>\n",
       "      <th>player_Alex Beach</th>\n",
       "      <th>...</th>\n",
       "      <th>sg_arg_min</th>\n",
       "      <th>sg_app_max</th>\n",
       "      <th>sg_app_med</th>\n",
       "      <th>sg_app_min</th>\n",
       "      <th>sg_ott_max</th>\n",
       "      <th>sg_ott_med</th>\n",
       "      <th>sg_ott_min</th>\n",
       "      <th>sg_t2g_max</th>\n",
       "      <th>sg_t2g_med</th>\n",
       "      <th>sg_t2g_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 547 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   player_Aaron Baddeley  player_Aaron Wise  player_Abraham Ancer  \\\n",
       "0                      1                  0                     0   \n",
       "1                      1                  0                     0   \n",
       "2                      1                  0                     0   \n",
       "3                      1                  0                     0   \n",
       "4                      1                  0                     0   \n",
       "\n",
       "   player_Adam Hadwin  player_Adam Long  player_Adam Schenk  \\\n",
       "0                   0                 0                   0   \n",
       "1                   0                 0                   0   \n",
       "2                   0                 0                   0   \n",
       "3                   0                 0                   0   \n",
       "4                   0                 0                   0   \n",
       "\n",
       "   player_Adam Scott  player_Adam Svensson  player_Akshay Bhatia  \\\n",
       "0                  0                     0                     0   \n",
       "1                  0                     0                     0   \n",
       "2                  0                     0                     0   \n",
       "3                  0                     0                     0   \n",
       "4                  0                     0                     0   \n",
       "\n",
       "   player_Alex Beach  ...  sg_arg_min  sg_app_max  sg_app_med  sg_app_min  \\\n",
       "0                  0  ...       -0.73        0.42       -0.39       -2.67   \n",
       "1                  0  ...       -0.72        0.42        0.07       -2.67   \n",
       "2                  0  ...       -0.94        0.42        0.19        0.07   \n",
       "3                  0  ...       -0.94        0.19        0.07       -1.81   \n",
       "4                  0  ...       -0.94        0.19        0.04       -1.81   \n",
       "\n",
       "   sg_ott_max  sg_ott_med  sg_ott_min  sg_t2g_max  sg_t2g_med  sg_t2g_min  \n",
       "0        0.60       -1.21       -2.04       -1.25       -2.33       -2.47  \n",
       "1        0.60       -0.22       -2.04       -0.86       -1.25       -2.47  \n",
       "2       -0.22       -0.35       -2.04       -0.86       -1.09       -1.25  \n",
       "3       -0.22       -0.35       -0.84       -0.86       -1.09       -1.58  \n",
       "4        0.08       -0.35       -0.84        0.38       -1.09       -1.58  \n",
       "\n",
       "[5 rows x 547 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_oh_minmax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh_minmax_features, test_oh_minmax_features, train_oh_minmax_target, test_oh_minmax_target = train_test_split(df_model_oh_minmax, df_model['strokes_rel_par'], test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 23605 rows and 23605 target measurements\n",
      "The test dataset has 2623 rows and 2623 target measurements\n"
     ]
    }
   ],
   "source": [
    "print('The train dataset has %s rows and %s target measurements' % (len(train_oh_minmax_features.iloc[:,0]), len(train_oh_minmax_target)))\n",
    "print('The test dataset has %s rows and %s target measurements' % (len(test_oh_minmax_features.iloc[:,0]), len(test_oh_minmax_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmoh_rmse = simple_rf_fit(train_features = train_oh_minmax_features, test_features = test_oh_minmax_features, \n",
    "                          train_target = train_oh_minmax_target, test_target = test_oh_minmax_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoding and Min-Max Ordering Percent Error Reduction: -14.43%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "error_pct_diff = round(100*(mmoh_rmse-base_rmse)/base_rmse, 2)\n",
    "\n",
    "print_string = '%s: %s' % ('One-Hot Encoding and Min-Max Ordering Percent Error Reduction', error_pct_diff)\n",
    "print(print_string+'%'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems as though ordering the strokes-gained features provides more information than leaving in the unique sequences (-15% versus -13%).  It could be that if we had significantly more data the reverse would be true.  However, I am sufficiently convinced that ordering the strokes-gained features results in a more accurate prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Made-Cut Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I have finalized the dataset and its features and am ready to begin modeling.  In the section below, I create a new feature called <em>place_class</em>.  This value will be equal to 1 when a player's finish for the tournament was less than 80, meaning the player made the cut.  \n",
    "\n",
    "In the training of an SVM, a number of metrics are available to use in the model's optimization.  There are 3 in particular that are common when evaluating a classification model's success:\n",
    "\n",
    "<ol>\n",
    "    <li>Accuracy: the number of correct predictions divided by the total number of records.</li>\n",
    "    <li>Precision: the number of correct positive predictions divided by the total number of predictions made asserting that the player would make the cut (i.e. of the made-cut predictions made by the model, how many of those players actually played the weekend?)</li>\n",
    "    <li>Recall: the number of correct positive predictions divided by the total number of players who made the cut (i.e. of the players who played the weekend, how many were predicted to do so?)</li>\n",
    "</ol>\n",
    "\n",
    "Above all else I want to know that when the model predicts a player to make the cut, he is indeed likely to play the weekend.  For that reason, I will use the <em>precision</em> scoring mode when training the model.  Below we will balance the number of class instances using synthetic minority oversampling (SMOTE) and train the classifier on the augmented dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['place_class'] = (df_model['place_adj'] < 80).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_imbalance = df_model[['place_class', 'player']].groupby('place_class').agg('count')\n",
    "class_imbalance.rename(columns = {'player':'record_count'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             record_count\n",
       "place_class              \n",
       "0                    9679\n",
       "1                   16549"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To balance the class count, we'll add 6870 SMOTE records from the negative scenarios.\n"
     ]
    }
   ],
   "source": [
    "upsample_count = class_imbalance.iloc[1]-class_imbalance.iloc[0]\n",
    "print(f\"To balance the class count, we'll add {upsample_count[0]} SMOTE records from the negative scenarios.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svm_features, df_svm_target = df_model_oh_minmax, df_model['place_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svm_features_SMOTE, df_svm_target_SMOTE = SMOTE.fit_resample(df_svm_features, df_svm_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before synthetic minority oversampling, there were 26228.  After, there are a total of 33098.\n"
     ]
    }
   ],
   "source": [
    "post_SMOTE_records, pre_SMOTE_records = df_svm_features_SMOTE.shape[0], df_svm_features.shape[0]\n",
    "\n",
    "print(f\"Before synthetic minority oversampling, there were {pre_SMOTE_records}.  After, there are a total of {post_SMOTE_records}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_svm_features, test_svm_features, train_svm_target, test_svm_target = train_test_split(df_svm_features_SMOTE, df_svm_target_SMOTE, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find a description of the hyperparameters I'll be tuning in the SVM, and I will initialize the hyperparameter dictionary to be searched through using Scikit-Learn's RandomSearchCV:\n",
    "\n",
    "<ol>\n",
    "    <li><em>C</em>: a regularization parameter which gives the model a sense for how important measuring a particular value accurately is.  The larger the value, the less-significant the regularization effect.</li>\n",
    "    <li><em>gamma</em>: influences the curvature of the radial and polynomial kernels</li>\n",
    "    <li><em>tol</em>: the tolerance for early stopping</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization constant\n",
    "C = [0.1, 1, 2, 5, 10]\n",
    "\n",
    "# Kernal coefficient\n",
    "gamma = ['scale', 'auto']\n",
    "\n",
    "# Stopping tolerance\n",
    "tol = [1e-4, 1e-3, 1e-2, 1e-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_svm_grid = {'C': C,\n",
    "                   'gamma': gamma,\n",
    "                   'tol': tol}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "svm_params, svm_error_metrics = svm_param_tune(train_features = train_svm_features, test_features = test_svm_features, \n",
    "                                               train_target = train_svm_target, test_target = test_svm_target, \n",
    "                                               random_grid = random_svm_grid, n_iter = 10, cv = 4, scoring = 'precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.0 %\n",
      "Precision: 82.1 %\n",
      "Recall: 55.9 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = svm_error_metrics[0]\n",
    "precision = svm_error_metrics[1]\n",
    "recall = svm_error_metrics[2]\n",
    "\n",
    "print(\"Accuracy: %s\" % round((100*accuracy),1), \"%\")\n",
    "print(\"Precision: %s\" % round((100*precision),1), \"%\")\n",
    "print(\"Recall: %s\" % round((100*recall),1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the results above, we see that the accuracy sits a bit above 70% while precisions north of 80%.  This means that we can have a strong degree of confidence that our prediction is correct when we pick our players who wsill make the cut.  While there is certainly more work that can be done to increase the odds of correctly picking a player to make the cut, these are compelling initial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\PGA Finish Projections\\\\svm_params.pkl', 'wb') as outfile:\n",
    "    pickle.dump(svm_params, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Made-Cut XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will train our model only on players who made the cut for a particular tournament.  By doing so, we will be able to run two models in succession: the first which picks players to make the cut, and the second to predict how well that player will finish.  We will begin by defining train and test sets for those players, and then conduct a random hyperparameter grid search for RandomForest and  XGBoost regressors.  We will measure results using standard root-mean-squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_made_cut_features, df_made_cut_target = df_model_oh_minmax.loc[df_model['place_class']==1], df_model['strokes_rel_par'].loc[df_model['place_class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xgreg_features, test_xgreg_features, train_xgreg_target, test_xgreg_target = train_test_split(df_made_cut_features, df_made_cut_target, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find a description of the hyperparameters I'll be tuning in the XGBoost regressor, and I will initialize the hyperparameter dictionary to be searched through using Scikit-Learn's RandomSearchCV:\n",
    "\n",
    "<ol>\n",
    "    <li><em>learning_rate</em>: the rate at which inaccurate predictions are considered in sequential tree additions in the boosted ensemble.  A low rate prevents overfitting, while a high rate can potentially increase accuracy.</li>\n",
    "    <li><em>n_estimators</em>: the number of trees added to the boosted ensemble.</li>\n",
    "    <li><em>min_child_weight</em>: a measure of how significant a prediction on a given leaf must be to be kept in the model.</li>\n",
    "    <li><em>gamma</em>: the minimum amount of loss reduction (i.e. information gain) that must be associated with a given split in any of the ensemble trees.</li>\n",
    "    <li><em>subsample</em>: the portion of records which is sampled for each boosted tree.</li>\n",
    "    <li><em>colsample_bytree</em>: the number of columns sampled in the training of each consecutive ensemble tree.</li>\n",
    "    <li><em>max_depth</em>: the maximum number of splits for a tree in the ensemble.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate\n",
    "learning_rate = [0.1, 0.2, 0.5]\n",
    "\n",
    "# Number of trees per forest\n",
    "n_estimators = [200, 500, 1000, 1500, 2000]\n",
    "\n",
    "# Minimum Child Weight\n",
    "min_child_weight = [10, 20, 30, 40]\n",
    "\n",
    "# Number of features evaluated at each node\n",
    "gamma = [0.1, 0.3, 0.5]\n",
    "\n",
    "# Subsample Ratio\n",
    "subsample = [0.4, 0.6, 0.8]\n",
    "\n",
    "# Column Sample Ratio\n",
    "colsample_bytree = [0.2, 0.6, 1]\n",
    "\n",
    "# Depth of each tree\n",
    "max_depth = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_xg_grid = {'learning_rate': learning_rate,\n",
    "                  'n_estimators': n_estimators,\n",
    "                  'min_child_weight': min_child_weight,\n",
    "                  'gamma': gamma,\n",
    "                  'subsample': subsample,\n",
    "                  'colsample_bytree': colsample_bytree,\n",
    "                  'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Tuned XG Boost Model with Player, Course, Tournament, and Lagged Strokes-Gained: -23.76%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_xgreg_params, xg_xgreg_error = xgb_param_tune(train_features = train_xgreg_features, train_target = train_xgreg_target, \n",
    "                                                 test_features = test_xgreg_features, test_target = test_xgreg_target,\n",
    "                                                 base_rmse = base_rmse, \n",
    "                                                 param_grid = random_xg_grid, n_iter = 40, cv = 4, verbose = 3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-Mean-Squared Strokes Relative to Par Error: 5.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Root-Mean-Squared Strokes Relative to Par Error: %s\" % round((xg_xgreg_error),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal XG Boost Regressor Hyperparameters: \n",
      "\n",
      "   subsample: 0.8\n",
      "\n",
      "   n_estimators: 1000\n",
      "\n",
      "   min_child_weight: 10\n",
      "\n",
      "   max_depth: 1\n",
      "\n",
      "   learning_rate: 0.2\n",
      "\n",
      "   gamma: 0.5\n",
      "\n",
      "   colsample_bytree: 0.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal XG Boost Regressor Hyperparameters:\", \"\\n\")\n",
    "\n",
    "for parameter in xg_xgreg_params:\n",
    "    print(\"   \", parameter, \": \", xg_xgreg_params[parameter], '\\n', sep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGR = XGBRegressor(subsample = xg_xgreg_params['subsample'], n_estimators = xg_xgreg_params['n_estimators'],\n",
    "                   min_child_weight = xg_xgreg_params['min_child_weight'], max_depth = xg_xgreg_params['max_depth'],\n",
    "                   learning_rate = xg_xgreg_params['learning_rate'], gamma = xg_xgreg_params['gamma'],\n",
    "                   colsample_bytree = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0.5, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.2, max_delta_step=0, max_depth=1,\n",
       "             min_child_weight=10, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=1000, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGR.fit(train_xgreg_features, train_xgreg_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = XGR.predict(test_xgreg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = pl.subplots(2)\n",
    "\n",
    "ax[0].hist(test_xgreg_target, bins = 20)\n",
    "ax[0].set(xlim = (-25, 25))\n",
    "ax[0].set_title('Strokes Relative to Par: Actual')\n",
    "ax[1].hist(predictions, bins = 20)\n",
    "ax[1].set(xlim = (-25, 25))\n",
    "ax[1].set_title('Strokes Relative to Par: Predicted')\n",
    "\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I'm feeling pretty great about the results!  With 80% recall of made cuts, a 70% rate of correctly predicting a made cut, and an average RMSE of 5 strokes, I feel comfortable continuing on with the rest of the work to build this model into a program which can make picks for me.  Below I have saved the models for future reference, and in later sections will begin researching the model's predictions on and for particular players and tournaments, and writing functions to feed inputs forward and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\PGA Finish Projections\\\\xgbr_params.pkl', 'wb') as outfile:\n",
    "    pickle.dump(xg_xgreg_params, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\PGA Finish Projections\\\\svm_params.pkl', 'rb') as infile:\n",
    "    svm_params = pickle.load(infile)\n",
    "    \n",
    "with open('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\PGA Finish Projections\\\\xgbr_params.pkl', 'rb') as infile:\n",
    "    xgbr_params = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(C = svm_params['C'], gamma = svm_params['gamma'], tol = svm_params['tol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma='auto')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.fit(df_svm_features_SMOTE, df_svm_target_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGR = XGBRegressor(subsample = xgbr_params['subsample'], n_estimators = xgbr_params['n_estimators'],\n",
    "                   min_child_weight = xgbr_params['min_child_weight'], max_depth = xgbr_params['max_depth'],\n",
    "                   learning_rate = xgbr_params['learning_rate'], gamma = xgbr_params['gamma'],\n",
    "                   colsample_bytree = xgbr_params['colsample_bytree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.6, gamma=0.5, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.2, max_delta_step=0, max_depth=1,\n",
       "             min_child_weight=10, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=1000, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGR.fit(df_made_cut_features, df_made_cut_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Cut_Classifier.pkl', 'wb') as outfile:\n",
    "    pickle.dump(SVM, outfile)\n",
    "    \n",
    "with open('Strokes_Regressor.pkl', 'wb') as outfile:\n",
    "    pickle.dump(XGR, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
