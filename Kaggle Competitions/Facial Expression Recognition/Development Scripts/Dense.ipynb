{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as pl\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization, Activation, Conv2D, Flatten, MaxPooling2D, AveragePooling2D, LeakyReLU, concatenate\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow import clip_by_value\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pq.ParquetDataset('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\Computer Vision\\\\Facial Expressions\\\\Training Data\\\\Images\\\\train_images.parquet').read().to_pandas()\n",
    "test_images = pq.ParquetDataset('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\Computer Vision\\\\Facial Expressions\\\\Training Data\\\\Images\\\\test_images.parquet').read().to_pandas()\n",
    "val_images = pq.ParquetDataset('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\Computer Vision\\\\Facial Expressions\\\\Training Data\\\\Images\\\\val_images.parquet').read().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pq.ParquetDataset('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\Computer Vision\\\\Facial Expressions\\\\Training Data\\\\Labels\\\\train_labels.parquet').read().to_pandas()\n",
    "test_labels = pq.ParquetDataset('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\Computer Vision\\\\Facial Expressions\\\\Training Data\\\\Labels\\\\test_labels.parquet').read().to_pandas()\n",
    "val_labels = pq.ParquetDataset('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\Computer Vision\\\\Facial Expressions\\\\Training Data\\\\Labels\\\\val_labels.parquet').read().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_images.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = Sequential()\n",
    "dnn.add(Dense(2500, input_shape=(input_shape,), activation=LeakyReLU(alpha=0.05)))\n",
    "dnn.add(Dropout(0.5))\n",
    "dnn.add(Dense(500, activation=LeakyReLU(alpha=0.05)))\n",
    "dnn.add(Dropout(0.5))\n",
    "dnn.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=0.000075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_history = dnn.fit(np.array(train_images), np.array(train_labels), validation_data=(np.array(test_images), np.array(test_labels)),\n",
    "                      batch_size = int(0.01*train_images.shape[0]), epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.save('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\Computer Vision\\\\Facial Expressions\\\\Models\\\\Dense\\\\Model.h5')\n",
    "with open('C:\\\\Users\\\\rbush\\\\Documents\\\\Projects\\\\Computer Vision\\\\Facial Expressions\\\\Models\\\\Dense\\\\Training History.pkl','wb') as outfile:\n",
    "    pickle.dump(dnn_history.history, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_predicted_categories = np.argmax(dnn.predict(val_images), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = np.argmax(np.array(val_labels), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_cm = confusion_matrix(dnn_predicted_categories, val_labels, labels=[0,1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_accuracy = (dnn_cm[0,0]+dnn_cm[1,1]+dnn_cm[2,2]+dnn_cm[3,3]+dnn_cm[4,4]+dnn_cm[5,5]+dnn_cm[6,6])/np.sum(dnn_cm)\n",
    "print(f'Dense-Net Accuracy: {round(100*dnn_accuracy,1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
